{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "**Before running this notebook, start TensorBoard in your terminal:**\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir logs/fit\n",
    "```\n",
    "\n",
    "Then open: **http://localhost:6006** in your browser\n",
    "\n",
    "TensorBoard will show training metrics as you run the cells below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard Introduction - Fashion-MNIST Classification\n",
    "# University at Buffalo - Neural Networks Lab\n",
    "\n",
    "In this lab, you'll train a fully connected neural network and use TensorBoard to visualize how different learning rates affect training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 03:33:55.998199: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-10 03:33:56.002158: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-10 03:33:56.011726: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-10 03:33:56.028469: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-10 03:33:56.028498: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-10 03:33:56.042590: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-10 03:33:57.224004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "\n",
    "print(\"Imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Training samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Fashion-MNIST: 70,000 grayscale images of 10 clothing categories\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Flatten images from 28x28 to 784-dimensional vectors\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# Class names for reference\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"Training samples: {x_train.shape[0]}\")\n",
    "print(f\"Test samples: {x_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Create a simple fully connected neural network.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Set Up TensorBoard\n",
    "\n",
    "**EXPERIMENT: Change the learning rate below and observe how it affects training!**  \n",
    "Try values like: 0.1, 0.01, 0.001, 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs will be saved to: logs/fit/20251210-034148_lr0.001\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Create a unique log directory for this run\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + f\"_lr{LEARNING_RATE}\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,  # Log weight histograms every epoch\n",
    "    write_graph=True   # Log the model graph\n",
    ")\n",
    "\n",
    "print(f\"TensorBoard logs will be saved to: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning rate: 0.001\n",
      "----------------------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.5436 - val_accuracy: 0.8487 - val_loss: 0.4172\n",
      "Epoch 2/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8597 - loss: 0.3874 - val_accuracy: 0.8457 - val_loss: 0.4152\n",
      "Epoch 3/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8729 - loss: 0.3470 - val_accuracy: 0.8667 - val_loss: 0.3604\n",
      "Epoch 4/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.3192 - val_accuracy: 0.8749 - val_loss: 0.3414\n",
      "Epoch 5/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.2989 - val_accuracy: 0.8773 - val_loss: 0.3376\n",
      "Epoch 6/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.2881 - val_accuracy: 0.8839 - val_loss: 0.3162\n",
      "Epoch 7/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.2723 - val_accuracy: 0.8818 - val_loss: 0.3249\n",
      "Epoch 8/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.2632 - val_accuracy: 0.8833 - val_loss: 0.3213\n",
      "Epoch 9/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.2533 - val_accuracy: 0.8911 - val_loss: 0.3132\n",
      "Epoch 10/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2420 - val_accuracy: 0.8869 - val_loss: 0.3254\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining with learning rate: {LEARNING_RATE}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.8783\n",
      "Test Loss: 0.3518\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's Never Too Late to Launch TensorBoard!\n",
    "\n",
    "If you haven't started TensorBoard yet, run this command in your terminal:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir logs/fit\n",
    "```\n",
    "\n",
    "Then open your browser to: **http://localhost:6006**\n",
    "\n",
    "Your training data is already saved - TensorBoard will show all your previous runs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Tasks\n",
    "\n",
    "1. Run this notebook with the default learning rate (0.01)\n",
    "2. Launch TensorBoard and observe the loss/accuracy curves\n",
    "3. Change `LEARNING_RATE` to 0.1 and run again\n",
    "4. Change `LEARNING_RATE` to 0.0001 and run again\n",
    "5. Compare all three runs in TensorBoard\n",
    "\n",
    "### Questions to Answer:\n",
    "- Which learning rate converges fastest?\n",
    "0.1\n",
    "- Which learning rate achieves the best final accuracy?\n",
    "0.001\n",
    "- Do any learning rates show signs of instability?\n",
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
